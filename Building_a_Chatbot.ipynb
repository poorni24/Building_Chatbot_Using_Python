{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWGoKv9swF2_",
        "outputId": "a3cad909-4553-4f7d-8d81-9c87a50a89ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('Chatbot.txt','r',errors = 'ignore')\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower() #Converts text to lowercase\n",
        "nltk.download('punkt') #Using the Punkt tokenizer\n",
        "nltk.download('wordnet') #Using the WordNet dictionary\n",
        "sentence_tokens = nltk.sent_tokenize(raw_doc) #Converts doc to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw_doc) #Converts doc to list of words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omkprMlC0DXP",
        "outputId": "3b0fde07-19ed-413b-8b71-6f657fa7ff9f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-tzsOAu1Am9",
        "outputId": "117bcec6-d558-42d1-e830-64252a4e867e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial intelligence (ai) is intelligence—perceiving, synthesizing, and inferring information—demonstrated by machines, as opposed to intelligence displayed by animals and humans.',\n",
              " 'example tasks in which this is done include speech recognition, computer vision, translation between (natural) languages, as well as other mappings of inputs.',\n",
              " 'the oxford english dictionary of oxford university press defines artificial intelligence as:[1]\\n\\nthe theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.',\n",
              " 'ai applications include advanced web search engines (e.g., google), recommendation systems (used by youtube, amazon and netflix), understanding human speech (such as siri and alexa), self-driving cars (e.g., waymo), automated decision-making and competing at the highest level in strategic game systems (such as chess and go).']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sltwnBMe1afL",
        "outputId": "44e16d0a-e010-478d-9a96-82c29ac4703b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['artificial', 'intelligence', '(', 'ai', ')', 'is']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "m7pxDkdz1d76"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",\"hii,how are you?\")\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greet(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "metadata": {
        "id": "zptal-fe1lfq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "JJcH81s4190D"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sentence_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response+\"I am sorry! I don't understand whatever you're saying!\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response+sentence_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "OK6WvDfb2AiD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "print(\"BOT: Hii, My name is Jane. Let's have a conversation! Also, if you wanna exit, just type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"BOT: You are welcome..\")\n",
        "        else:\n",
        "            if(greet(user_response)!=None):\n",
        "                print(\"BOT: \"+greet(user_response))\n",
        "            else:\n",
        "                sentence_tokens.append(user_response)\n",
        "                word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "                final_words=list(set(word_tokens))\n",
        "                print(\"BOT: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sentence_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"BOT: Goodbye! Get you soon!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRrBTA9Q2Nui",
        "outputId": "8b86f7f8-a1ad-4dc6-dbab-6972f4daceed"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: Hii, My name is Jane. Let's have a conversation! Also, if you wanna exit, just type Bye!\n",
            "greetings\n",
            "BOT: hi\n",
            "history\n",
            "BOT: evaluating approaches to ai\n",
            "no established unifying theory or paradigm has guided ai research for most of its history.\n",
            "warfare\n",
            "BOT: warfare\n",
            "as technology and research evolve and the world enters the third revolution of warfare following gunpowder and nuclear weapons, the artificial intelligence arms race ensues between the united states, china, and russia, three countries with the world's top five highest military budgets.\n",
            "thanks\n",
            "BOT: You are welcome..\n",
            "BOT: Hii, My name is Jane. Let's have a conversation! Also, if you wanna exit, just type Bye!\n",
            "\n",
            "BOT: I am sorry! I don't understand whatever you're saying!\n",
            "bye\n",
            "BOT: Goodbye! Get you soon!\n"
          ]
        }
      ]
    }
  ]
}